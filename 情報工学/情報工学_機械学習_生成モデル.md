# 生成モデル [generative model]（執筆中...）
機械学習を生成モデル手法（GAN、VAE等）について勉強したことをまとめたノート（忘備録）です。現在執筆中<br>

## 目次 [Contents]

1. 生成モデルの概要
1. [VAE [Variational AutoEncoder]](#VAE)
    1. VAE のアーキテクチャ
    1. VAE の学習とKLダイバージェンス
    1. 潜在変数の空間と生成画像の分布の関係
1. [GAN [Generative Adversarial Networks]](#GAN)
    1. GAN のアーキテクチャ
    1. 識別器の動作と損失関数
    1. 生成器の動作と損失関数
    1. モード崩壊
1. [DCGAN [Deep Convolutional GAN]](#DCGAN)
    1. DCGAN のアーキテクチャ
    1. [DCGAN の適用例](#DCGANの適用例)
1. WGAN [Wasserstein GAN]
1. Conditional GAN [Conditional Generative Adversarial Nets]
1. pix2pix
1. [補足事項](#補足事項)
    1. [【補足】KLダイバージェンス [Kullback-Leibler(KL) diviergence]](#KLダイバージェンス)
    1. [【補足】JSダイバージェンス [Jensen-Shannon(JS) divergence]](#JSダイバージェンス)
    1. [【補足（外部リンク）】情報理論 / 情報数理](http://yagami12.hatenablog.com/entry/2017/09/17/103228)
1. [参考サイト](#参考)

---

<a id="VAE"></a>

## ■ VAE [Variational AutoEncoder]

### ◎ VAE のアーキテクチャ
（生成モデルの分野における）オートエンコーダーとは、教師なし学習のもとで、データを表現するための特徴を獲得するために、以下のようなアーキテクチャと処理手順を持った手法である。<br>

![image](https://user-images.githubusercontent.com/25688193/56261188-05248e00-6115-11e9-9ee8-c4ebe45b67dc.png)<br>

【オートエンコーダーの処理手順】<br>
1. 入力データ（上図では手書き数字画像データ）x を、エンコーダー（ニューラルネットワーク）で潜在変数 z に変換する。<br>
	この様子は、見方を変えると入力データの符号化しているようにみなせるため、この入力データを変換するニューラルネットワークをエンコーダーと呼ぶ。<br>
    又、潜在変数 z の次元が、入力データ x より小さい場合、このエンコーダーでの処理は次元削除になっているとみなすことも出来る。<br>
1. 潜在変数 z を、デコーダー（ニューラルネットワーク）に入力し、元の画像に再変換する。<br>
    この様子は、見方を変えるとエンコーダーで符号化した潜在変数を、再度（入力データである画像に）復号化しているようにみなせるため、この潜在変数を変換するニューラルネットワークをデコーダーと呼ぶ。<br>

<br>

このようなオートエンコーダーの内、以下のようなアーキテクチャ図のように、潜在変数 z の分布を正規分布 N(0,1) に押し込めてめた（ z~N(0,1)  ）オートエンコーダーを、VAE [Variational AutoEncoder] という。<br>
（これに対して、通常の AutoEncoder は潜在変数 z の分布を仮定していない。）<br>

![image](https://user-images.githubusercontent.com/25688193/56263330-82540100-611d-11e9-8adf-2b944d51df56.png)<br>

※ ここで、VAE におけるエンコーダーは、正規分布に従う潜在変数 z を直接出力するのではなく、潜在変数 z が従う正規分布の平均値 μ(x) と分散値 σ(x) を生成していることに注意。<br>

### ◎ VAE の学習とKLダイバージェンス
VAE の学習の目的は、潜在変数 z から画像を生成する確率分布 p_θ (x) の最大化である。<br>
但し、確率分布のままでは扱いづらいため、その対数尤度 ![image](https://user-images.githubusercontent.com/25688193/56268166-b1716f00-612b-11e9-96f6-e219ce7af871.png) の最大化を考える。<br>

結論から述べると、この対数尤度 ![image](https://user-images.githubusercontent.com/25688193/56268166-b1716f00-612b-11e9-96f6-e219ce7af871.png) は、以下の式ように、変分下限 [ELBO : Evidence Lower BOund] なるものととKLダイバージェンスの和で表現できる。（詳細計算略）<br>
![image](https://user-images.githubusercontent.com/25688193/56268264-dd8cf000-612b-11e9-88a3-52169bd47f44.png)<br>

ここで、KLダイバージェンスの項 ![image](https://user-images.githubusercontent.com/25688193/56268329-07dead80-612c-11e9-8a6c-49949d8b5470.png) はその定義より、常に０以上の値となるが、VAE の学習の目的である、![image](https://user-images.githubusercontent.com/25688193/56268673-e03c1500-612c-11e9-8022-a4c2974fd409.png) のときは０の値となるので、対数尤度 ![image](https://user-images.githubusercontent.com/25688193/56268166-b1716f00-612b-11e9-96f6-e219ce7af871.png) を最大化したければ、変分下限 L(θ,ϕ,x) を最大化すれば良いことが分かる。<br>

次に、この変分下限 L(θ,ϕ,x) は、以下の式に変形出来る。（詳細計算略）<br>
![image](https://user-images.githubusercontent.com/25688193/56268734-0cf02c80-612d-11e9-89b8-92d02bad08f3.png)<br>

従って、変分下限 L(θ,ϕ,x)  を最大化するためには、KLダイバージェンスを最小化し、復元誤差を最大化すれば良いことが分かる。<br>

まとめると、VAE の学習の目的である対数尤度 ![image](https://user-images.githubusercontent.com/25688193/56268166-b1716f00-612b-11e9-96f6-e219ce7af871.png) の最大化したければ、変分下限 L(θ,ϕ,x) を最大化すれば良いが、<br>
そのためには、２つの確率分布 ![image](https://user-images.githubusercontent.com/25688193/56268861-550f4f00-612d-11e9-96bd-fc7fe83cc895.png) のKLダイバージェンス<br>
![image](https://user-images.githubusercontent.com/25688193/56268970-8d169200-612d-11e9-82fc-b09556914cd9.png)<br>
を最小化し、<br>
復元誤差<br>
![image](https://user-images.githubusercontent.com/25688193/56268998-a15a8f00-612d-11e9-9935-a448a70220c8.png)<br>
を最大化すれば良いこととになる。<br>

### ◎ 潜在変数の空間と生成画像の分布の関係
以下の図は、潜在変数 z の次元を２次元として、エンコーダー側から正規分布に従って出力される潜在変数 z の値と、実際にデコーダーから出力される画像の対応関係を示した図である。<br>

![image](https://user-images.githubusercontent.com/25688193/56263478-0908de00-611e-11e9-890a-d34fbc180164.png)<br>

エンコーダーから出力される潜在変数 z の空間において、正規分布 N(0,1) の密度が大きい領域（＝中央部分）では、3,5,8,9,2 の画像などの似た形状の画像の種類が多く分布していることがわかる。反対に、1,7,0 などの似ていない形状の画像の種類は、正規分布の密度が小さい領域に分布していることが分かる。<br>

<br>

更に、以下の左下図は、潜在変数 z の次元を２次元として、潜在変数 z の値を動かした場合（赤矢印）の、デコーダー側から出力される出力画像の変化を表した図である。<br>
![image](https://user-images.githubusercontent.com/25688193/56262854-7e26e400-611b-11e9-88d6-05e974c449a6.png)<br>
先のエンコーダー側から出力される潜在変数の値の分布図（右上図）と、概ね一致していることが分かる。<br>


<a id="GAN"></a>

## ■ GAN [Generative Adversarial Networks]

### ◎ GAN のアーキテクチャ
![image](https://user-images.githubusercontent.com/25688193/56257395-051d9180-6107-11e9-9a0c-0ca2bd6e98db.png)<br>

### ◎ 識別器の動作と損失関数
識別器の損失関数は、以下のような式で与えられる。<br>
![image](https://user-images.githubusercontent.com/25688193/55678554-ef55e280-5936-11e9-88ec-1916b5c622e8.png)<br>

ここで、この損失関数の式は、以下のような識別器の動作の意味に対応している。<br>
① 識別器は、本物画像 x が入力されたとき、本物画像 x を（正しく）本物に判定するように D(x)=1.0 を出力しようとする。<br>
⇒ 第１項 ![image](https://user-images.githubusercontent.com/25688193/55678563-0268b280-5937-11e9-9bff-5dea501a52f8.png) の最大化に対応<br>

② 識別器は、偽物画像 G(z) が入力されたとき、偽物画像 G(z) を（正しく）偽物に判定するように ![image](https://user-images.githubusercontent.com/25688193/55678572-25936200-5937-11e9-874b-8be18f59938f.png) を出力しようとする。<br>
⇒ 第２項 ![image](https://user-images.githubusercontent.com/25688193/55678567-144a5580-5937-11e9-92d0-ea53e0378846.png) の最大化に対応<br>

![image](https://user-images.githubusercontent.com/25688193/55678606-86229f00-5937-11e9-99d8-cb378c5e8c6b.png)<br>


### ◎ 生成器の動作と損失関数
> 記載中...

<a id="DCGAN"></a>

## ■ DCGAN [Deep Convolutional GAN]
> 記載中...

<a id="DCGANの適用例"></a>

## ☆ DCGAN の適用例

- [DCGAN を利用した手書き文字（MNIST）の自動生成](https://github.com/Yagami360/MachineLearning_Exercises_Python_PyTorch/tree/master/GAN_DCGAN_PyTorch)


<a id="補足事項"></a>

## ■ 補足事項

<a id="KLダイバージェンス"></a>

### ◎ KLダイバージェンス [Kullback-Leibler(KL) diviergence]
２つの確率分布 P,Q 間の距離を表す指標として、KLダイバージェンスと呼ばれる以下のような指標が考えられる。<br>

![image](https://user-images.githubusercontent.com/25688193/56255740-ee743c00-6100-11e9-9e09-3574daab5b09.png)<br>

※ ここで、定義から分かるように、KLダイバージェンスは、２つの確率分布 P,Q に対して、対称ではない。（![image](https://user-images.githubusercontent.com/25688193/56255798-25e2e880-6101-11e9-9ff6-5abfdd6e8b82.png)）これは、例えば、A地点からB地点までの距離と、その反対のB地点からA地点までの距離が異なることを意味している。従って、距離の公理を満たしていないことになり、厳密には距離ではないことになるが、便宜上、統計的距離という。<br>

以下の図は、２つの確率分布 P,Q の具体的な確率分布の形状として、いくつかの正規分布でKLダイバージェンスを求めた図である。<br>

![image](https://user-images.githubusercontent.com/25688193/56255881-7d815400-6101-11e9-9b4a-a563413e4030.png)<br>

２つの確率分布 P,Q が完全に一致するとき、０の値となっており、<br>
２つの確率分布 P,Q が重ならない部分が大きくなるにつれ、大きな値となっていることが分かる。<br>

#### ☆ KLダイバージェンスとエントロピーの関係
KLダイバージェンスは、クロスエントロピーとエントロピーの差で記述することも出来る。<br>
即ち、エントロピーは<br>
![image](https://user-images.githubusercontent.com/25688193/56255899-95f16e80-6101-11e9-9791-95c012937999.png)<br>
クロスエントロピーは、<br>
![image](https://user-images.githubusercontent.com/25688193/56255930-ab669880-6101-11e9-9e78-d06bfecee5c4.png)<br>
であることより、<br>
![image](https://user-images.githubusercontent.com/25688193/56255946-bb7e7800-6101-11e9-9633-beb2a3426628.png)<br>
となり、従って、<br>
![image](https://user-images.githubusercontent.com/25688193/56255976-d6e98300-6101-11e9-9b53-a2304f892bc7.png)<br>
の関係が成り立つことがわかる。<br>


<a id="JSダイバージェンス"></a>

### ◎ JSダイバージェンス [Jensen-Shannon(JS) divergence]
KLダイバージェンスは、距離の公理の一つである対称性の性質を満たさない（![image](https://user-images.githubusercontent.com/25688193/56255798-25e2e880-6101-11e9-9ff6-5abfdd6e8b82.png)）ので、扱いづらいという問題があった。<br>
（※この対称性の性質を満たさないことは、例えば、A地点からB地点までの距離と、その反対のB地点からA地点までの距離が異なることを意味している。　）

JSダイバージェンスは、対称性の性質を満たすように、KLダイバージェンスを使って、以下のように定義される２つの確率分布 P,Q 間の距離指標である。<br>
![image](https://user-images.githubusercontent.com/25688193/56256830-3d23d500-6105-11e9-8d7d-4f101841b809.png)<br>

以下の図は、２つの確率分布 P,Q の具体的な確率分布の形状として、いくつかの正規分布でKLダイバージェンスとJSダイバージェンスを求めた図である。<br>

![image](https://user-images.githubusercontent.com/25688193/56256902-87a55180-6105-11e9-8e34-782283dc391a.png)<br>

黄色枠で示した確率分布は、２つの確率分布 P,Q の平均値である M である。<br>
この平均分布 M は、各々の確率分布 P,Q から見て対称であるが、<br>
JSダイバージェンスでは、その定義式より、（対称である）平均分布 M と各々の確率分布 P, Q とのKLダイバージェンスを計算することで、対称性の性質を満たすようにしていることがわかる。<br>


<a id="参考"></a>

## ■ 参考

### ◎ 参考サイト

**強調文字**付きは、特に参考にさせたもらったサイトです。<br>

- 全般
    - [**GAN（と強化学習との関係）**](https://www.slideshare.net/masa_s/gan-83975514)
    - [今さら聞けないGAN（1）　基本構造の理解](https://qiita.com/triwave33/items/1890ccc71fab6cbca87e)

- VAE
    - [**Variational Autoencoder徹底解説**](https://qiita.com/kenmatsu4/items/b029d697e9995d93aa24)
    - [**猫でも分かるVariational AutoEncoder**](https://www.slideshare.net/ssusere55c63/variational-autoencoder-64515581)

- GAN
    - [GANの論文を読んだ自分なりの理解とTensorflowでのGANの実装メモ](http://owatank.hatenablog.com/entry/2018/04/20/180151)

- その他
    - [正規分布間のKLダイバージェンス](https://qiita.com/ceptree/items/9a473b5163d5655420e8)
    - [KL divergenceとJS divergenceの可視化](http://yusuke-ujitoko.hatenablog.com/entry/2017/05/07/200022)

- 実装
    - [**PyTorch (12) Generative Adversarial Networks (MNIST) - 人工知能に関する断創録**](http://aidiary.hatenablog.com/entry/20180304/1520172429)
    - [PyTorch (11) Variational Autoencoder - 人工知能に関する断創録](http://aidiary.hatenablog.com/entry/20180228/1519828344)
