# 生成モデル [generative model]（執筆中...）
機械学習を生成モデル手法（GAN、VAE等）について勉強したことをまとめたノート（忘備録）です。現在執筆中<br>

## 目次 [Contents]

1. 生成モデルの概要
1. [変分オートエンコーダー [VAE : Variational AutoEncoder]](#VAE)
    1. VAE のアーキテクチャ
    1. VAE の学習とKLダイバージェンス
    1. 潜在変数の空間と生成画像の分布の関係
1. [GAN [Generative Adversarial Networks]](#GAN)
    1. [GAN のアーキテクチャ](#GANのアーキテクチャ)
    1. [識別器の動作と損失関数](#識別器の動作と損失関数)
    1. [生成器の動作と損失関数](#生成器の動作と損失関数)
    1. [密度比推定による識別器の役割の再解釈](#密度比推定による識別器の役割の再解釈)
    1. [JSダイバージェンスによる識別器の損失関数の再解釈](#JSダイバージェンスによる識別器の損失関数の再解釈)
    1. [GANの学習の困難さ](#GANの学習の困難さ)
        1. [GANの収束性](#GANの収束性)
        1. [モード崩壊](#モード崩壊)
        1. [勾配損失問題](#勾配損失問題)
1. [DCGAN [Deep Convolutional GAN]](#DCGAN)
    1. DCGAN のアーキテクチャ
    1. [DCGAN の適用例](#DCGANの適用例)
1. [WGAN [Wasserstein GAN]](#WGAN)
    1. [JSダイバージェンスと Earth-Mover 距離の収束性と勾配消失問題](#JSダイバージェンスとEarth-Mover距離の収束性の違いと勾配消失問題)
    1. [WGAN のアーキテクチャと損失関数](#WGANのアーキテクチャと損失関数)
1. Conditional GAN [Conditional Generative Adversarial Nets]
1. pix2pix
1. 論文翻訳
    1. [【論文翻訳（非公開）】Generative Adversarial Networks](https://github.com/Yagami360/MachineLearning-Papers_Survey/blob/master/papers/Generative%20Adversarial%20Networks/Generative%20Adversarial%20Networks.md)
    1. [【論文翻訳（非公開）】Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks](https://github.com/Yagami360/MachineLearning-Papers_Survey/blob/master/papers/Unsupervised%20Representation%20Learning%20with%20Deep%20Convolutional%20Generative%20Adversarial%20Networks/DeepConvolutionalGAN.md)
    1. [【論文翻訳（非公開）】Wasserstein GAN](https://github.com/Yagami360/MachineLearning-Papers_Survey/blob/master/papers/Wasserstein%20GAN/WassersteinGAN.md)
1. [補足事項](#補足事項)
    1. [【補足】KLダイバージェンス [Kullback-Leibler(KL) diviergence]](#KLダイバージェンス)
    1. [【補足】JSダイバージェンス [Jensen-Shannon(JS) divergence]](#JSダイバージェンス)
    1. [【補足】Earth-Mover 距離（Wassertein距離）](#EMD)
    1. [【補足（外部リンク）】情報理論 / 情報数理](http://yagami12.hatenablog.com/entry/2017/09/17/103228)
    1. [【補足（外部リンク）】ゲーム理論](http://yagami12.hatenablog.com/entry/2018/03/02/171939)
1. [参考サイト](#参考)

---

<a id="VAE"></a>

## ■ 変分オートエンコーダー [VAE : Variational AutoEncoder]

### ◎ VAE のアーキテクチャ
（生成モデルの分野における）オートエンコーダーとは、教師なし学習のもとで、データを表現するための特徴を獲得するために、以下のようなアーキテクチャと処理手順を持った手法である。<br>

![image](https://user-images.githubusercontent.com/25688193/56261188-05248e00-6115-11e9-9ee8-c4ebe45b67dc.png)<br>

【オートエンコーダーの処理手順】<br>
1. 入力データ（上図では手書き数字画像データ）x を、エンコーダー（ニューラルネットワーク）で潜在変数 z に変換する。<br>
	この様子は、見方を変えると入力データの符号化しているようにみなせるため、この入力データを変換するニューラルネットワークをエンコーダーと呼ぶ。<br>
    又、潜在変数 z の次元が、入力データ x より小さい場合、このエンコーダーでの処理は次元削除になっているとみなすことも出来る。<br>
1. 潜在変数 z を、デコーダー（ニューラルネットワーク）に入力し、元の画像に再変換する。<br>
    この様子は、見方を変えるとエンコーダーで符号化した潜在変数を、再度（入力データである画像に）復号化しているようにみなせるため、この潜在変数を変換するニューラルネットワークをデコーダーと呼ぶ。<br>

<br>

このようなオートエンコーダーの内、以下のようなアーキテクチャ図のように、潜在変数 z の分布を正規分布 N(0,1) に押し込めてめた（ z~N(0,1)  ）オートエンコーダーを、VAE [Variational AutoEncoder] という。<br>
（これに対して、通常の AutoEncoder は潜在変数 z の分布を仮定していない。）<br>

![image](https://user-images.githubusercontent.com/25688193/56263330-82540100-611d-11e9-8adf-2b944d51df56.png)<br>

※ ここで、VAE におけるエンコーダーは、正規分布に従う潜在変数 z を直接出力するのではなく、潜在変数 z が従う正規分布の平均値 μ(x) と分散値 σ(x) を生成していることに注意。<br>

### ◎ VAE の学習とKLダイバージェンス
VAE の学習の目的は、潜在変数 z から画像を生成する確率分布 p_θ (x) の最大化である。<br>
但し、確率分布のままでは扱いづらいため、その対数尤度 ![image](https://user-images.githubusercontent.com/25688193/56268166-b1716f00-612b-11e9-96f6-e219ce7af871.png) の最大化を考える。<br>

結論から述べると、この対数尤度 ![image](https://user-images.githubusercontent.com/25688193/56268166-b1716f00-612b-11e9-96f6-e219ce7af871.png) は、以下の式ように、変分下限 [ELBO : Evidence Lower BOund] なるものととKLダイバージェンスの和で表現できる。（詳細計算略）<br>
![image](https://user-images.githubusercontent.com/25688193/56268264-dd8cf000-612b-11e9-88a3-52169bd47f44.png)<br>

ここで、KLダイバージェンスの項 ![image](https://user-images.githubusercontent.com/25688193/56268329-07dead80-612c-11e9-8a6c-49949d8b5470.png) はその定義より、常に０以上の値となるが、VAE の学習の目的である、![image](https://user-images.githubusercontent.com/25688193/56268673-e03c1500-612c-11e9-8022-a4c2974fd409.png) のときは０の値となるので、対数尤度 ![image](https://user-images.githubusercontent.com/25688193/56268166-b1716f00-612b-11e9-96f6-e219ce7af871.png) を最大化したければ、変分下限 L(θ,ϕ,x) を最大化すれば良いことが分かる。<br>

次に、この変分下限 L(θ,ϕ,x) は、以下の式に変形出来る。（詳細計算略）<br>
![image](https://user-images.githubusercontent.com/25688193/56268734-0cf02c80-612d-11e9-89b8-92d02bad08f3.png)<br>

従って、変分下限 L(θ,ϕ,x)  を最大化するためには、KLダイバージェンスを最小化し、復元誤差を最大化すれば良いことが分かる。<br>

まとめると、VAE の学習の目的である対数尤度 ![image](https://user-images.githubusercontent.com/25688193/56268166-b1716f00-612b-11e9-96f6-e219ce7af871.png) の最大化したければ、変分下限 L(θ,ϕ,x) を最大化すれば良いが、<br>
そのためには、２つの確率分布 ![image](https://user-images.githubusercontent.com/25688193/56268861-550f4f00-612d-11e9-96bd-fc7fe83cc895.png) のKLダイバージェンス<br>
![image](https://user-images.githubusercontent.com/25688193/56268970-8d169200-612d-11e9-82fc-b09556914cd9.png)<br>
を最小化し、<br>
復元誤差<br>
![image](https://user-images.githubusercontent.com/25688193/56268998-a15a8f00-612d-11e9-9935-a448a70220c8.png)<br>
を最大化すれば良いこととになる。<br>

### ◎ 潜在変数の空間と生成画像の分布の関係
以下の図は、潜在変数 z の次元を２次元として、エンコーダー側から正規分布に従って出力される潜在変数 z の値と、実際にデコーダーから出力される画像の対応関係を示した図である。<br>

![image](https://user-images.githubusercontent.com/25688193/56263478-0908de00-611e-11e9-890a-d34fbc180164.png)<br>

エンコーダーから出力される潜在変数 z の空間において、正規分布 N(0,1) の密度が大きい領域（＝中央部分）では、3,5,8,9,2 の画像などの似た形状の画像の種類が多く分布していることがわかる。反対に、1,7,0 などの似ていない形状の画像の種類は、正規分布の密度が小さい領域に分布していることが分かる。<br>

<br>

更に、以下の左下図は、潜在変数 z の次元を２次元として、潜在変数 z の値を動かした場合（赤矢印）の、デコーダー側から出力される出力画像の変化を表した図である。<br>
![image](https://user-images.githubusercontent.com/25688193/56262854-7e26e400-611b-11e9-88d6-05e974c449a6.png)<br>
先のエンコーダー側から出力される潜在変数の値の分布図（右上図）と、概ね一致していることが分かる。<br>


<a id="GAN"></a>

## ■ GAN [Generative Adversarial Networks]

<a id="GANのアーキテクチャ"></a>

### ◎ GAN のアーキテクチャ
![image](https://user-images.githubusercontent.com/25688193/56257395-051d9180-6107-11e9-9a0c-0ca2bd6e98db.png)<br>
![image](https://user-images.githubusercontent.com/25688193/56270630-8ab63700-6131-11e9-82c4-0caff170a43e.png)<br>


<a id="識別器の動作と損失関数"></a>

### ◎ 識別器の動作と損失関数
識別器の損失関数は、以下のような式で与えられる。<br>
![image](https://user-images.githubusercontent.com/25688193/55678554-ef55e280-5936-11e9-88ec-1916b5c622e8.png)<br>

ここで、この損失関数の式は、以下のような識別器の動作の意味に対応している。<br>
① 識別器は、本物画像 x が入力されたとき、本物画像 x を（正しく）本物に判定するように D(x)=1.0 を出力しようとする。<br>
⇒ 第１項 ![image](https://user-images.githubusercontent.com/25688193/55678563-0268b280-5937-11e9-9bff-5dea501a52f8.png) の最大化に対応<br>

② 識別器は、偽物画像 G(z) が入力されたとき、偽物画像 G(z) を（正しく）偽物に判定するように ![image](https://user-images.githubusercontent.com/25688193/55678572-25936200-5937-11e9-874b-8be18f59938f.png) を出力しようとする。<br>
⇒ 第２項 ![image](https://user-images.githubusercontent.com/25688193/55678567-144a5580-5937-11e9-92d0-ea53e0378846.png) の最大化に対応<br>

![image](https://user-images.githubusercontent.com/25688193/55678606-86229f00-5937-11e9-99d8-cb378c5e8c6b.png)<br>


<a id="生成器の動作と損失関数"></a>

### ◎ 生成器の動作と損失関数
![image](https://user-images.githubusercontent.com/25688193/56271987-b38bfb80-6134-11e9-9053-092bc8d798db.png)<br>

> 記載中...

<a id="密度比推定による識別器の役割の再解釈"></a>

### ◎ 密度比推定による識別器の役割の再解釈
ここでは、密度比推定の観点から、GANにおける識別器が果たす役割を、理論的に再解釈する。

先の VAE では、デコーダー側での潜在変数 z から画像を生成する確率分布 p_θ (x) が、正規分布やベルヌーイ分布の形になると仮定した上で、その確率分布の対数尤度を最大化するように学習していた。<br>

一方、GANでは、このような生成器の確率分布 ![image](https://user-images.githubusercontent.com/25688193/56272299-62c8d280-6135-11e9-8467-89448e51e0d0.png) の具体的な形を仮定することなしに、暗黙的な生成モデルとして考えている。<br>
従って、VAEのときのように、確率分布の対数尤度 ![image](https://user-images.githubusercontent.com/25688193/56272169-1f6e6400-6135-11e9-8ad7-c4ff1eb0c28e.png) を直接評価できないので、モデルの分布 ![image](https://user-images.githubusercontent.com/25688193/56272299-62c8d280-6135-11e9-8467-89448e51e0d0.png) と真の分布 ![image](https://user-images.githubusercontent.com/25688193/56272229-3ca33280-6135-11e9-8682-7ab994fc852f.png) の密度比<br>
![image](https://user-images.githubusercontent.com/25688193/56272333-77a56600-6135-11e9-8e19-728221fc907b.png)<br>
でモデルの分布がどのくらい真の分布っぽいかの尤度を評価することになる。<br>

ここで、データ集合 X のうち、<br>
半分のデータがモデルの分布 ![image](https://user-images.githubusercontent.com/25688193/56272299-62c8d280-6135-11e9-8467-89448e51e0d0.png) から生成されてものと考え、そのラベルを y=0 とし、<br>
もう半分のデータが真の分布 ![image](https://user-images.githubusercontent.com/25688193/56272229-3ca33280-6135-11e9-8682-7ab994fc852f.png) から生成されてものと考え、そのラベルを y=1 とすると、<br>
モデルの分布と真の分布は、ラベルが設定された際の条件付き確率分布<br>
![image](https://user-images.githubusercontent.com/25688193/56272437-a9b6c800-6135-11e9-8d73-9695403240ea.png)<br>
で表現できる。<br>

従って、密度比の式は、<br>
![image](https://user-images.githubusercontent.com/25688193/56272551-e2ef3800-6135-11e9-85a0-36c6526f3cd0.png)<br>
つまり、観測データ x が、モデルの分布 ![image](https://user-images.githubusercontent.com/25688193/56272299-62c8d280-6135-11e9-8467-89448e51e0d0.png) から来たのか？真の分布 ![image](https://user-images.githubusercontent.com/25688193/56272229-3ca33280-6135-11e9-8682-7ab994fc852f.png) から来たのか？を予想するような**識別モデル**<br>
![image](https://user-images.githubusercontent.com/25688193/56272572-fbf7e900-6135-11e9-8825-6d826fa79631.png)<br>
を学習出来れば、密度比を推定することが出来る。<br>
この識別モデルこれはまさに、先に述べた識別器 D そのもの役割であり、従って、識別器 D は、密度比を推定しているともみなすことも出来る。<br>
※ 識別器によって、GAN における尤度推定を、NNが得意としている分類問題に置き換えている点に注目。<br>


<a id="JSダイバージェンスによる識別器の損失関数の再解釈"></a>

### ◎ JSダイバージェンスによる識別器の損失関数の再解釈
GAN の学習の目的は、モデルの分布と真の分布を近づけ ![image](https://user-images.githubusercontent.com/25688193/56332861-ea155500-61cc-11e9-8032-98293e456e86.png) とすることである。このことは、以下で見るようにモデルの分布と真の分布間のJSダイバージェンスを最小化していることに一致する。<br>

真の分布 ![image](https://user-images.githubusercontent.com/25688193/56272229-3ca33280-6135-11e9-8682-7ab994fc852f.png) とモデルの分布 ![image](https://user-images.githubusercontent.com/25688193/56272299-62c8d280-6135-11e9-8467-89448e51e0d0.png) との間のJSダイバージェンスは、<br>

![image](https://user-images.githubusercontent.com/25688193/56332894-02856f80-61cd-11e9-9b0d-1e8993fbae3e.png)<br>

ここで、上式の赤字の項 ![image](https://user-images.githubusercontent.com/25688193/56332952-3cef0c80-61cd-11e9-8cc2-78d1f05581a7.png) は、識別器の損失関数そのものであるので、損失関数を最小化することは、JSダイバージェンスを最小化することと等価であることが分かる。<br>
そして、このJSダイバージェンスを最小化することは、モデルの分布と真の分布の２つの分布を一致させることであるので、<br>
結局のところ、<br>
「GANの学習の目的であるモデルの分布と真の分布を近づけ ![image](https://user-images.githubusercontent.com/25688193/56332861-ea155500-61cc-11e9-8032-98293e456e86.png) とすること。」<br>
⇔「（真の分布とモデルの分布の）JSダイバージェンスを最小化すること。」<br>
⇔「（識別器の）損失関数を最小化すること。」<br>
の関係が成り立つことが分かる。<br>

<a id="GANの収束性"></a>

### ◎ GANの学習の困難さ
GANの学習の難しさの要因には、大きく分けて以下のような要因がある。

- 損失関数の収束性の問題
- モード崩壊
- 勾配損失問題
- 生成画像のクオリティーの評価が、損失関数から判断し難い


<a id="GANの収束性"></a>

#### ☆ GANの収束性
GANの学習の難しさの１つの要因に、損失関数の収束性の問題がある。<br>

- GANは、識別器と生成器の２人プレイヤーゼロサムゲームになっているが、このゲームの最適解は、ナッシュ均衡点になる。<br>

- ２人プレイヤーゼロサムゲームのナッシュ均衡点は、鞍点になる。<br>
    ![image](https://user-images.githubusercontent.com/25688193/56336649-213f3280-61dc-11e9-8b55-9360b88fcc82.png)<br>

- 識別器の損失関数<br>
    ![image](https://user-images.githubusercontent.com/25688193/56336686-3f0c9780-61dc-11e9-9719-49f1faf7b2d5.png)<br>
    の形状が、上図のような凸関数であれば、SGDによってナッシュ均衡点（＝鞍点）に収束されることが保証されるが、非凸関数の場合は、保証されない。（GANではニューラルネットワークにより損失関数を表現するので、関数の形状は非凸関数）<br>

- このような非凸関数に対して、SGDで最適化（＝鞍点の探査）を行っていくと、ナッシュ均衡点（＝鞍点）に行かず、振動する可能性がある。<br>
    例えば、損失関数が L(a,b)=a×b という単純な形であった場合にも、SGDで生成器と識別器を交互に最適化していくと、以下の図のように、損失関数の値が発散する。<br>
    ![image](https://user-images.githubusercontent.com/25688193/56336712-4f247700-61dc-11e9-9557-f4f661c2d747.png)<br>

<a id="モード崩壊"></a>

#### ☆ モード崩壊 [Mode collapse]
学習が不十分な識別器に対して、生成器を最適化した場合や、生成器への入力ノイズ z の潜在変数としての次元が足りたていない場合などにおいて、生成器による生成画像が、ある特定の画像（例えば、MNISTでは数字の３などの特定の画像）に集中してしまい、学習用データが本来持っている多様な種類の画像（例えば、MNISTでは数字の0~9の画像）を生成できなくなってしまう問題がある。<br>
GANにおいて発生するこのような問題を、モード崩壊といい、GANの学習の困難さの要因の１つになっている。<br>
※ ここでいうモード（流行）とは、最頻出値のこと。<br>

<!--
> 自作の図を要追加
![image](https://user-images.githubusercontent.com/25688193/56337604-10dd8680-61e1-11e9-8c81-fdb1090c67e2.png)<br>
-->

<a id="勾配損失問題"></a>

#### ☆ 勾配損失問題
先に見たように、学習が十分でない識別器に対して、生成器を最適化すると、モード崩壊が発生してしまう。<br>
それを防ぐために、ある生成器 G の状態に対しての識別器を完全に学習すると、今度は勾配損失問題が発生してしまう。<br>
このように、GANでは、モード崩壊と勾配損失問題が互いに反して発生してしまうというジレンマを抱えている。<br>

> 記載中...


<a id="DCGAN"></a>

## ■ DCGAN [Deep Convolutional GAN]
> 記載中...

<a id="DCGANの適用例"></a>

## ☆ DCGAN の適用例

- [DCGAN を利用した手書き文字（MNIST）の自動生成](https://github.com/Yagami360/MachineLearning_Exercises_Python_PyTorch/tree/master/GAN_DCGAN_PyTorch)


<a id="WGAN"></a>

## ■ WGAN [Wasserstein GAN]
既存のGANにおける（識別器の）学習は、先で見たように、JSダイバージェンスを最小化していることと同値であった。<br>
しかしながら、このJSダイバージェンスの最小化に基づく学習では、以下のような問題点が存在する。（詳細は後述）<br>

- 真の分布 ![image](https://user-images.githubusercontent.com/25688193/56465577-00c0e380-643b-11e9-9cc9-4b1ebdea24f4.png) とモデルの分布 ![image](https://user-images.githubusercontent.com/25688193/56465585-20580c00-643b-11e9-9695-94b89982a71f.png) の台（Supp）が重ならない場合において、勾配損失問題が発生する。<br>

- 学習回数に対する loss 値の変化の様子が、生成画像のクオリティに比例しない。<br>

そこで、Wasserein GAN では、JSダイバージェンスではなく、Earth-Mover 距離（EMD）（＝Wassertein距離ともいう）と呼ばれる別の距離指標を使用する。
（※厳密には、このWassertein距離の双対表現の式を近似した式）<br>
これにより、既存の GAN（＝JSダイバージェンス最小化）で発生する上記の問題を回避することが出来る。<br>


<a id="JSダイバージェンスとEarth-Mover距離の収束性の違いと勾配消失問題"></a>

### ◎ JSダイバージェンスとEarth-Mover距離の収束性の違いと勾配消失問題
概略で挙げたように、従来のGANにおける問題点の１つは、<br>

- 真の分布とモデルの分布の台が重ならない場合において、勾配消失問題が発生する。<br>

という問題である。<br>
ここでは、この問題点の詳細と、WGANにおける解決策を見ていく。<br>

![image](https://user-images.githubusercontent.com/25688193/56465595-60b78a00-643b-11e9-841d-e4e704f29b57.png)<br>

GANでの学習の目的は、真の分布 ![image](https://user-images.githubusercontent.com/25688193/56465577-00c0e380-643b-11e9-9cc9-4b1ebdea24f4.png) とモデルの分布 ![image](https://user-images.githubusercontent.com/25688193/56465585-20580c00-643b-11e9-9695-94b89982a71f.png) の２つの確率分布を互いに一致させることであるが、この２つの確率分布の台（Suup）が、上図のように互いに重ならない場合を考える。<br>
※ θ は、生成器のニューラルネットワークの重みパラメーター<br>

このような２つの確率分布の台が交わらない極端なケースの例として、以下のような図のようなケースで、JSダイバージェンスを計算する。<br>

![image](https://user-images.githubusercontent.com/25688193/56465614-f18e6580-643b-11e9-9ab3-5d67522c4e75.png)<br>

![image](https://user-images.githubusercontent.com/25688193/56465620-04089f00-643c-11e9-8eeb-be4c269fd7ce.png)<br>

この計算結果を図示すると、以下のような図となる。<br>

![image](https://user-images.githubusercontent.com/25688193/56465640-4c27c180-643c-11e9-8103-8dcc5f8afaba.png)<br>

真の分布とモデルの分布が重なる θ=0 の部分で、JSダイバージェンスの値が不連続となっている。一方、真の分布とモデルの分布が重ならない θ≠0 の部分では、JSダイバージェンスの値が一定値となっていることが分かる。<br>
※ この様子を確率分布の系列 ![image](https://user-images.githubusercontent.com/25688193/56465651-842f0480-643c-11e9-97f1-4947a7f7399a.png) で考えると、この系列は、JSダイバージェンスのもとで、θ_t→0 で収束していないとも言える。<br>

ここで、GANの目的は、真の分布とモデルの分布を一致させるでことあり、これをJSダイバージェンスの最小化で行っていた。<br>
しかしながら、上図では、学習の余地がある、真の分布とモデルの分布が重ならない θ≠0 の部分において、JSダイバージェンスの値が一定値となっているために、その勾配の値が０になっていまうために、結果として、JSダイバージェンスを最小化して、誤差逆伝搬で学習するのに必要な勾配値が得られないという、いわゆる勾配消失問題が発生していることが分かる。<br>

このように、真の分布とモデルの分布の台（Supp）が互いに重ならない場合において、従来のGANのJSダイバージェンスの最小化による学習では、勾配消失問題が発生してしまう。<br>

<br>

Wassertein GAN では、この勾配消失問題を回避するために、Earth-Mover距離（Wassertein距離）を使用するが、このEarth-Mover距離（Wassertein距離）は、以下のように定義される。<br>

![image](https://user-images.githubusercontent.com/25688193/56477963-17704480-64e6-11e9-9396-a72c7cae56af.png)<br>

このEarth-Mover距離を、先のJSダイバージェンスと同様にして、２つの確率分布の台が交わらない極端なケースで計算すると、<br>
![image](https://user-images.githubusercontent.com/25688193/56480315-7b016e80-64f4-11e9-860e-fd3963c90c7a.png)<br>
となる。<br>
この計算結果を図示すると、以下のような図となる。<br>
![image](https://user-images.githubusercontent.com/25688193/56480337-8eacd500-64f4-11e9-908a-cde46f6e8743.png)<br>

真の分布とモデルの分布が重なる θ=0 の部分で、EMDの値が０なっている。
一方、真の分布とモデルの分布が重ならない θ≠0 の部分では、EMDの勾配が一定値となっていることが分かる。<br>
つまり、学習が完了していない、真の分布とモデルの分布が重ならない領域において、誤差逆伝搬での学習に必要な、EMDの勾配値が得られているので、勾配消失問題は発生していないことが分かる。<br>


<a id="WGANのアーキテクチャと損失関数"></a>

### ◎  WGANのアーキテクチャと損失関数
先でみたように、Wassertein GAN では、以下のように定義される、Earth-Mover距離（Wassertein距離）を使用する。<br>

![image](https://user-images.githubusercontent.com/25688193/56480424-f82ce380-64f4-11e9-9952-d4f72fbd4aaa.png)<br>

但し、この式では、GANで扱うような画像の次元が大きい場合に、現実的に計算可能ではないので、この式の双対表現の式を利用する。<br>
※ このEarth-Mover距離を計算することは、線形計画法を解くことに一致するので、元の式（主問題）に対する双対表現が得られる。<br>
即ち、<br>
![image](https://user-images.githubusercontent.com/25688193/56480447-11359480-64f5-11e9-9ff8-71541144ff8d.png)<br>

ここで、関数 ![image](https://user-images.githubusercontent.com/25688193/56480469-30342680-64f5-11e9-8519-a93d37cfc1ba.png) は、K-リプシッツ連続な関数であることが、元のEarth-Mover距離の制約条件から要請される。<br>

※ また、このリプシッツ連続性の条件は、先の勾配消失問題の例でみたように、一定の勾配が得られて学習がうまくいくための要件になっているとみなすことも出来る。<br>

![image](https://user-images.githubusercontent.com/25688193/56480747-6a51f800-64f6-11e9-83d2-c9679c340cff.png)<br>

WGANでは、上図のアーキテクチャ図のように、このリプシッツ連続な関数 f を、
ニューラルネットワークで構成されたクリティック（＝従来の識別器）で表現する。<br>
※ このクリティックは、従来のGANの識別器のように、入力データが本物か偽物かの 0 or 1 の２値を sigmoid 活性化関数で出力するのではなく、連続値を出力とする。そのため、もはや従来の識別器とは異なる機能となっているため、識別器ではなくクリティックという。<br>

このとき、クリティックのニューラルネットワークの重みパラメーターを w とし、この関数 f をパラメーター付きの関数 f_w  で表記すると、先の Earth-Mover 距離の双対表現の式は、以下の式で近似できる。<br>


> 記載中...


<a id="補足事項"></a>

## ■ 補足事項

<a id="KLダイバージェンス"></a>

### ◎ KLダイバージェンス [Kullback-Leibler(KL) diviergence]
２つの確率分布 P,Q 間の距離を表す指標として、KLダイバージェンスと呼ばれる以下のような指標が考えられる。<br>

![image](https://user-images.githubusercontent.com/25688193/56255740-ee743c00-6100-11e9-9e09-3574daab5b09.png)<br>

※ ここで、定義から分かるように、KLダイバージェンスは、２つの確率分布 P,Q に対して、対称ではない。（![image](https://user-images.githubusercontent.com/25688193/56255798-25e2e880-6101-11e9-9ff6-5abfdd6e8b82.png)）これは、例えば、A地点からB地点までの距離と、その反対のB地点からA地点までの距離が異なることを意味している。従って、距離の公理を満たしていないことになり、厳密には距離ではないことになるが、便宜上、統計的距離という。<br>

以下の図は、２つの確率分布 P,Q の具体的な確率分布の形状として、いくつかの正規分布でKLダイバージェンスを求めた図である。<br>

![image](https://user-images.githubusercontent.com/25688193/56255881-7d815400-6101-11e9-9b4a-a563413e4030.png)<br>

２つの確率分布 P,Q が完全に一致するとき、０の値となっており、<br>
２つの確率分布 P,Q が重ならない部分が大きくなるにつれ、大きな値となっていることが分かる。<br>

#### ☆ KLダイバージェンスとエントロピーの関係
KLダイバージェンスは、クロスエントロピーとエントロピーの差で記述することも出来る。<br>
即ち、エントロピーは<br>
![image](https://user-images.githubusercontent.com/25688193/56255899-95f16e80-6101-11e9-9791-95c012937999.png)<br>
クロスエントロピーは、<br>
![image](https://user-images.githubusercontent.com/25688193/56255930-ab669880-6101-11e9-9e78-d06bfecee5c4.png)<br>
であることより、<br>
![image](https://user-images.githubusercontent.com/25688193/56255946-bb7e7800-6101-11e9-9633-beb2a3426628.png)<br>
となり、従って、<br>
![image](https://user-images.githubusercontent.com/25688193/56255976-d6e98300-6101-11e9-9b53-a2304f892bc7.png)<br>
の関係が成り立つことがわかる。<br>


<a id="JSダイバージェンス"></a>

### ◎ JSダイバージェンス [Jensen-Shannon(JS) divergence]
KLダイバージェンスは、距離の公理の一つである対称性の性質を満たさない（![image](https://user-images.githubusercontent.com/25688193/56255798-25e2e880-6101-11e9-9ff6-5abfdd6e8b82.png)）ので、扱いづらいという問題があった。<br>
（※この対称性の性質を満たさないことは、例えば、A地点からB地点までの距離と、その反対のB地点からA地点までの距離が異なることを意味している。　）

JSダイバージェンスは、対称性の性質を満たすように、KLダイバージェンスを使って、以下のように定義される２つの確率分布 P,Q 間の距離指標である。<br>
![image](https://user-images.githubusercontent.com/25688193/56256830-3d23d500-6105-11e9-8d7d-4f101841b809.png)<br>

以下の図は、２つの確率分布 P,Q の具体的な確率分布の形状として、いくつかの正規分布でKLダイバージェンスとJSダイバージェンスを求めた図である。<br>

![image](https://user-images.githubusercontent.com/25688193/56256902-87a55180-6105-11e9-8e34-782283dc391a.png)<br>

黄色枠で示した確率分布は、２つの確率分布 P,Q の平均値である M である。<br>
この平均分布 M は、各々の確率分布 P,Q から見て対称であるが、<br>
JSダイバージェンスでは、その定義式より、（対称である）平均分布 M と各々の確率分布 P, Q とのKLダイバージェンスを計算することで、対称性の性質を満たすようにしていることがわかる。<br>


<a id="EMD"></a>

### ◎ Earth-Mover距離（Wassertein距離）
Earth-Mover距離（Wassertein距離）は、２つの確率分布間の距離指標の１つであるが、下図のように、確率分布を１つの山とみなすと、片方の確率分布の山をもう片方の確率分布の山に，土を輸送して変形させるための最小の労力であるという最適輸送問題ともみなせる。<br>
（※それ故、Earth-Mover という名前がついている。）<br>

![image](https://user-images.githubusercontent.com/25688193/56466456-69b15700-644d-11e9-869d-6c6ebf66279d.png)<br>

![image](https://user-images.githubusercontent.com/25688193/56466469-88afe900-644d-11e9-9a29-4f37e14e1b4b.png)<br>

![image](https://user-images.githubusercontent.com/25688193/56466479-bdbc3b80-644d-11e9-9a23-c143b4f06f8d.png)<br>

そして、Earth-Mover距離（EMD,Wassertein距離）は、この 「（輸送する労力）＝（輸送する土の量）×（輸送する距離）」 の関係において、全ての組み合わせで総和した以下のような式で定義できる。<br>

![image](https://user-images.githubusercontent.com/25688193/56477963-17704480-64e6-11e9-9396-a72c7cae56af.png)<br>

２つの確率分布の山を一致させるさせるためには、無数の方法が考えられるが、そららの方法の中で最小の労力（＝最小のEMD）で済むような、最適な輸送方法を考えるのが、考えるべき最適輸送問題となる。<br>

そして、この最適輸送問題は、一般的な線形計画法を用いて解くことが出来る。<br>

しかし、結論から述べると、この最適輸送問題を、単純に線形計画法の主形式で解く方法では、GANのように確率変数 x,y の次元が大きい場合には、その計算量が現実的ではなくなる。<br>
一方、この線形計画問題の双対形式で与える式では、現実的に計算可能な式になっている。<br>

そして、この線形計画法の双対形式での、
Earth-Mover距離（EMD,Wassertein距離）の式は、以下のようになる。（式の導出略）<br>

![image](https://user-images.githubusercontent.com/25688193/56466815-c151c180-6451-11e9-8474-4fb0e160df4e.png)<br>

※ 関数 f のリプシッツ連続性の要件は、線形計画問題おける制約条件から発生している。<br>


<a id="参考"></a>

## ■ 参考

### ◎ 参考サイト

**強調文字**付きは、特に参考にさせたもらったサイトです。<br>

- 全般
    - [**GAN（と強化学習との関係）**](https://www.slideshare.net/masa_s/gan-83975514)
    - [**今さら聞けないGAN（1）　基本構造の理解**](https://qiita.com/triwave33/items/1890ccc71fab6cbca87e)
    - [タカハシ春の GAN 祭り！〜 一日一GAN(๑•̀ㅂ•́)و✧ 〜- ABEJA Arts Blog](https://tech-blog.abeja.asia/entry/everyday_gan)

- VAE
    - [**Variational Autoencoder徹底解説**](https://qiita.com/kenmatsu4/items/b029d697e9995d93aa24)
    - [**猫でも分かるVariational AutoEncoder**](https://www.slideshare.net/ssusere55c63/variational-autoencoder-64515581)

- GAN
    - [**Generative Adversarial Networks(GAN)を勉強して、kerasで手書き文字生成する - 緑茶思考ブログ**](http://yusuke-ujitoko.hatenablog.com/entry/2017/05/08/010314)
    - [GANの論文を読んだ自分なりの理解とTensorflowでのGANの実装メモ](http://owatank.hatenablog.com/entry/2018/04/20/180151)

- Wasserstein GAN
    - [**Read-through: Wasserstein GAN**](https://www.alexirpan.com/2017/02/22/wasserstein-gan.html)
    - [**From GAN to WGAN**](https://lilianweng.github.io/lil-log/2017/08/20/from-GAN-to-WGAN.html)
    - [GAN — Wasserstein GAN & WGAN-GP](https://medium.com/@jonathan_hui/gan-wasserstein-gan-wgan-gp-6a1a2aa1b490)
    - [**Wasserstein GAN と Kantorovich-Rubinstein 双対性 - Qiita**](https://qiita.com/mittyantest/items/0fdc9ce7624dbd2ee134)
    - [**[DL輪読会]Wasserstein GAN/Towards Principled Methods for Training Generative Adversarial Networks**](https://www.slideshare.net/DeepLearningJP2016/dlwasserstein-gantowards-principled-methods-for-training-generative-adversarial-networks)
    - [Wasserstein GAN（WGAN）でいらすとや画像を生成してみる - 緑茶思考ブログ](http://yusuke-ujitoko.hatenablog.com/entry/2017/05/20/145924)
    - [Wasserstein GAN [arXiv:1701.07875] – ご注文は機械学習ですか？](http://musyoku.github.io/2017/02/06/Wasserstein-GAN/)
    - [Wasserstein GAN (WGAN) - DeepLearningを勉強する人](http://wanwannodao.hatenablog.com/entry/2017/02/28/051353)

- その他
    - [**KL divergenceとJS divergenceの可視化**](http://yusuke-ujitoko.hatenablog.com/entry/2017/05/07/200022)
    - [正規分布間のKLダイバージェンス](https://qiita.com/ceptree/items/9a473b5163d5655420e8)

- 実装
    - [**PyTorch (12) Generative Adversarial Networks (MNIST) - 人工知能に関する断創録**](http://aidiary.hatenablog.com/entry/20180304/1520172429)
    - [PyTorch (11) Variational Autoencoder - 人工知能に関する断創録](http://aidiary.hatenablog.com/entry/20180228/1519828344)
